# 1. on-policy(同策略)： 要learn的agent和环境互动的agent是同一个时，对应的policy。
# 2. off-policy(异策略)： 要learn的agent和环境互动的agent不是同一个时，对应的policy。
# 3. important sampling（重要性采样）： 使用另外一种数据分布，来逼近所求分布的一种方法，在强化学习中通常和蒙特卡罗方法结合使用，公式如下：\int f(x) p(x) d x=\int f(x) \frac{p(x)}{q(x)} q(x) d x=E_{x \sim q}[f(x){\frac{p(x)}{q(x)}}]=E_{x \sim p}[f(x)]∫f(x)p(x)dx=∫f(x) 
# 4. Proximal Policy Optimization (PPO)： 避免在使用important sampling时由于在 \thetaθ 下的 p_{\theta}\left(a_{t} | s_{t}\right)p 
